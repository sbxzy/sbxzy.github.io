.. pygks documentation master file, created by
   sphinx-quickstart on Mon Jul 18 15:15:54 2016.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

=================================
Welcome to pygks's documentation!
=================================

Installation Guide
=================================

This package depends on Python2.7, numpy, sklearn and python-graph. After the installation of Python 2.7, the other packages can be installed automatically with setuptools as follows.

.. code-block:: c

   pip install numpy
   pip install sklearn
   pip install matplotlib
   
Python-graph can be downloaded from the link (also provided in the prerequisites folder of pygks):

http://code.google.com/p/python-graph/

After downloading, switch to the 'core' directory and run:

.. code-block:: c

   python setup.py install
   
Finally, after installing all the required packages, we can switch to the package directory and install the pygks package.

.. code-block:: c

   cd Software directory/pygks_package
   python setup.py install
   
Overview
=================================

This package implements the Growing Neural Gas (GNG), single layered Self-Organizing Incremental Neural Network (SOINN). Kernel Density Estimation (KDE), and Semi-Supervised Gaussian kernel smoothed (SSL-GKS) regression. Moreover, there are some usefull tools for high dimensional data visualization and density visualization.

If there's any questions, please contact me at: lordxzy@qq.com.

Examples
=================================
The following is an example of regression and drawing a 2d density contour.

.. code-block:: python

	from pygks.utils import csv_reader
	from pygks.reg_gng import GNGregressor
	from numpy import array
	
	r = csv_reader('reg_intro.csv')
	X,y = r.separate_label()
	the_reg = GNGregressor(smooth = -0.5, age_max = 200, nn_lambda = 60)
	the_reg.fit(X,y)
	test_x = []
	draw_x = []
	for i in range(100):
	test_x.append(array([i/100.0]))
	draw_x.append(i/100.0)
	test_y = the_reg.predict(test_x)
	r2 = csv_reader('reg_intro.csv')
	testX, testY = r2.separate_label()
	from sklearn.metrics import mean_squared_error
	print mean_squared_error(testY,the_reg.predict(testX))
	import matplotlib.pyplot as plt
	fig = plt.figure()
	r_draw = csv_reader('reg_intro.csv')
	X_raw = r_draw.get_all()
	X_draw = []
	i = 0
	for each in X_raw:
		if i % 3 == 0:
			X_draw.append(X_raw[i])
		i += 1
	print X_raw[0]
	ax = fig.add_subplot(111)
	for i in range(len(X_draw)):
		ax.plot(X_draw[i][0], X_draw[i][1], '.', color = '0.8')
		ax.plot(draw_x,test_y,'k-')
	plt.show()
	the_reg.draw_density()
	
The output is:

.. code-block:: python

	training with bandwidth calculation, please wait...
	end round!
	time cost 0.599024057388
	0.0097513650717
	[ 0.         -0.12730268]
	
	
.. image::
   regression.png

.. image::
   density.png
	
This is another example of drawing SOINN training result.

.. code-block:: python

   from pygks.utils import csv_reader
   from pygks.ui_isoinn import data_block
   from numpy import array
   
   r = csv_reader('wine_train.csv')
   data = r.get_all()
   nn_model = data_block(data, age_max = 200, nn_lambda = 70)
   nn_model.draw_2d()
   
The output is:
	
.. image::
  2d.png
  
Another example of semi-supervised SOINN regression:

.. code-block:: python

   from pygks.reg_inn import ISOINNregressor
   from numpy import array
   from pygks.utils import csv_reader
   from sklearn.metrics import mean_squared_error
   from numpy import isnan,isinf
   
   r1 = csv_reader('wine_train.csv')
   r2 = csv_reader('wine_test.csv')
   
   trainX, trainy = r1.separate_label()
   testX, testy = r2.separate_label()
   nnReg = ISOINNregressor(K = 30, age_max = 300, nn_lambda = 350, alpha = 10, smooth = None,  del_noise = True)
   nnReg.fit(trainX, trainy)
   
   print len(testX[0]),'dimension'
   print len(nnReg.nodes),'nodes'
   predicty = nnReg.predict(testX)
   delets = []
   i = 0
   for each in predicty:
      if isnan(each) or isinf(each):
         print(i,each,'error after density estimation')
         delets.append(i)
      i += 1
   
   for i in range(len(delets)):
      testy.pop(delets[i]-i)
      predicty.pop(delets[i]-i)
   
   print len(delets),'failed points'
   print mean_squared_error(testy,predicty)
   
The output is:

.. code-block:: python

   training with bandwidth calculation, please wait...
   end training SOINN!
   time cost 1.40131592751
   11 dimension
   107 nodes
   end training SOINN!
   0 failed points
   0.0125627244183

Package Contents
=================================

.. toctree::
   :maxdepth: 2
   
.. automodule:: pygks.utils
   :members:
   
.. automodule:: pygks.gks
   :members:
   
.. automodule:: pygks.kde
   :members:
   
.. automodule:: pygks.reg_gng
   :members:
   
.. automodule:: pygks.reg_inn
   :members:
   
.. automodule:: pygks.ui_gng
   :members:
   
.. automodule:: pygks.ui_isoinn
   :members:
   
.. automodule:: pygks.gng2
   :members:
   
.. automodule:: pygks.isoinn2
   :members:

Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`

